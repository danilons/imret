{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import caffe\n",
    "import scipy\n",
    "import glob\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caffe.set_mode_cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fnames = [('indoor', fname) for fname in glob.glob('../data/scene/test/indoor/*.jpg')] + [('outdoor', fname) for fname in glob.glob('../data/scene/test/outdoor/*.jpg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/scene/scene.json', 'r') as fp:\n",
    "    predictions = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nets = {'indoor': caffe.Net('../data/scene/indoor/deploy.prototxt',\n",
    "                            '../data/scene/indoor/snapshot_iter_1025.caffemodel',\n",
    "                             caffe.TEST),\n",
    "        \n",
    "        'outdoor': caffe.Net('../data/scene/outdoor/deploy.prototxt',\n",
    "                             '../data/scene/outdoor/snapshot_iter_4230.caffemodel',\n",
    "                             caffe.TEST)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transformers = {}\n",
    "\n",
    "with open('../data/scene/indoor/mean.binaryproto', 'rb') as f:\n",
    "    blob = caffe.proto.caffe_pb2.BlobProto()\n",
    "    blob.MergeFromString(f.read())\n",
    "    mean_image = np.reshape(blob.data, (3, 384, 384))\n",
    "    data_shape = tuple((1, 3, 384, 384))\n",
    "    assert len(data_shape) == 4, 'Bad data shape.'\n",
    "    mean_image = mean_image.astype(np.uint8)\n",
    "    mean_image = mean_image.transpose(1, 2, 0)\n",
    "    shape = list(mean_image.shape)\n",
    "    mean_image = scipy.misc.imresize(mean_image, (data_shape[2], data_shape[3]))\n",
    "    mean_image = mean_image.transpose(2, 0, 1)\n",
    "    mean_image = mean_image.astype('float')\n",
    "\n",
    "transformer = caffe.io.Transformer({'data': nets['indoor'].blobs['data'].data.shape})\n",
    "transformer.set_transpose('data', (2, 0, 1))\n",
    "transformer.set_channel_swap('data', (2, 1, 0))\n",
    "transformer.set_mean('data', mean_image)\n",
    "\n",
    "transformers['indoor'] = transformer\n",
    "\n",
    "with open('../data/scene/outdoor/mean.binaryproto', 'rb') as f:\n",
    "    blob = caffe.proto.caffe_pb2.BlobProto()\n",
    "    blob.MergeFromString(f.read())\n",
    "    mean_image = np.reshape(blob.data, (3, 384, 384))\n",
    "    data_shape = tuple((1, 3, 384, 384))\n",
    "    assert len(data_shape) == 4, 'Bad data shape.'\n",
    "    mean_image = mean_image.astype(np.uint8)\n",
    "    mean_image = mean_image.transpose(1, 2, 0)\n",
    "    shape = list(mean_image.shape)\n",
    "    mean_image = scipy.misc.imresize(mean_image, (data_shape[2], data_shape[3]))\n",
    "    mean_image = mean_image.transpose(2, 0, 1)\n",
    "    mean_image = mean_image.astype('float')\n",
    "\n",
    "transformer = caffe.io.Transformer({'data': nets['outdoor'].blobs['data'].data.shape})\n",
    "transformer.set_transpose('data', (2, 0, 1))\n",
    "transformer.set_channel_swap('data', (2, 1, 0))\n",
    "transformer.set_mean('data', mean_image)\n",
    "\n",
    "transformers['outdoor'] = transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_mask(image, pixel_value, color):\n",
    "    w, h = image.shape\n",
    "    m1 = np.zeros((w, h), image.dtype)\n",
    "    m2 = np.zeros((w, h, 3), image.dtype)\n",
    "\n",
    "    x, y = np.where(image == pixel_value)\n",
    "    m1[x, y] = 1\n",
    "    m2[x, y, :] = color\n",
    "    return m1, m2\n",
    "\n",
    "def chunks(lst, size):\n",
    "    for i in range(0, len(lst), size):\n",
    "        yield lst[i:i + size]\n",
    "\n",
    "def segment_objects(fname, scene):\n",
    "    image = cv2.imread(fname)\n",
    "    transformed_image = transformers[scene].preprocess('data', image[:, :, (2, 1, 0)])\n",
    "    net[scene].blobs['data'].data[0] = transformed_image\n",
    "    output = net.forward()\n",
    "    segmented = output['fc_final_up']\n",
    "    return segmented[0].argmax(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = caffe.Net('../data/scene/preposition/deploy.prototxt',\n",
    "                '../data/scene/preposition/snapshot_iter_780.caffemodel',\n",
    "                caffe.TEST)\n",
    "\n",
    "with open('../data/scene/preposition/mean.binaryproto', 'rb') as f:\n",
    "    blob = caffe.proto.caffe_pb2.BlobProto()\n",
    "    blob.MergeFromString(f.read())\n",
    "    mean_image = np.reshape(blob.data, (3, 256, 256))\n",
    "    data_shape = tuple((1, 3, 227, 227))\n",
    "    assert len(data_shape) == 4, 'Bad data shape.'\n",
    "    mean_image = mean_image.astype(np.uint8)\n",
    "    mean_image = mean_image.transpose(1, 2, 0)\n",
    "    shape = list(mean_image.shape)\n",
    "    mean_image = scipy.misc.imresize(mean_image, (data_shape[2], data_shape[3]))\n",
    "    mean_image = mean_image.transpose(2, 0, 1)\n",
    "    mean_image = mean_image.astype('float')\n",
    "\n",
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "transformer.set_transpose('data', (2, 0, 1))\n",
    "transformer.set_channel_swap('data', (2, 1, 0))\n",
    "transformer.set_mean('data', mean_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = {}\n",
    "with open('../data/scene/outdoor/labels.txt', 'r') as fp:\n",
    "    labels['outdoor'] = dict([line.replace('#', '').replace(':', '').strip().split() for line in fp.readlines()])\n",
    "\n",
    "with open('../data/scene/indoor/labels.txt', 'r') as fp:\n",
    "    labels['indoor'] = dict([line.replace('#', '').replace(':', '').strip().split() for line in fp.readlines()])\n",
    "    \n",
    "inv_labels = {}\n",
    "inv_labels['outdoor'] ={v: k for k, v in outdoor.items()}\n",
    "inv_labels['indoor'] ={v: k for k, v in indoor.items()}\n",
    "\n",
    "labels['indoor'] = {int(k): v for k, v in labels['indoor'].items()}\n",
    "labels['outdoor'] = {int(k): v for k, v in labels['outdoor'].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/scene/preposition/labels.txt') as fp:\n",
    "    labels_preposition = [line.strip().replace('_', ' ') for line in fp.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/4269\n",
      "../data/scene/test/indoor/a_airlock_airlock_000212.jpg\n"
     ]
    }
   ],
   "source": [
    "alpha = .4\n",
    "indexed = []\n",
    "images = []\n",
    "objects = []\n",
    "batch_size = 32\n",
    "    \n",
    "for nn, (scene, fname) in enumerate(fnames):\n",
    "    if nn % 100 == 0:\n",
    "        print \"Processed {}/{}\".format(nn, len(fnames))\n",
    "    name = os.path.basename(fname)\n",
    "    prediction = predictions.get(name)\n",
    "    if prediction is None:\n",
    "        continue\n",
    "    if prediction != scene:\n",
    "        segmented = segment_objects(fname, scene=prediction)\n",
    "    else:\n",
    "        segmented = cv2.imread(os.path.join(\"../data/scene/output-seg/\", scene + \"-bw\", name.replace(\".jpg\", \".png\")), 0)\n",
    "    \n",
    "    if segmented is None:\n",
    "        print \"Segmentation {} not found\".format(fname)\n",
    "        break\n",
    "    \n",
    "    fullname = os.path.join('../data/scene/test/', scene, name.replace('.png', '.jpg'))\n",
    "    print(fullname)\n",
    "    image = cv2.imread(fullname)\n",
    "    image = scipy.misc.imresize(image, segmented.shape, interp='bilinear')\n",
    "    \n",
    "    for (x1, x2) in itertools.permutations(np.unique(segmented), 2):\n",
    "        obj1 = labels[prediction][x1]\n",
    "        obj2 = labels[prediction][x2]\n",
    "\n",
    "        mask1, overlay1 = create_mask(segmented, x1, color=(255, 0, 0))\n",
    "        mask2, overlay2 = create_mask(segmented, x2, color=(0, 0, 255))\n",
    "\n",
    "        img1 = cv2.bitwise_and(image, image, mask=mask1)\n",
    "        img2 = cv2.bitwise_and(image, image, mask=mask2)\n",
    "        img = cv2.bitwise_or(img1, img2)\n",
    "        cv2.addWeighted(overlay1, alpha, img, 1 - alpha, 0, img)\n",
    "        cv2.addWeighted(overlay2, alpha, img, 1 - alpha, 0, img)\n",
    "        img = scipy.misc.imresize(img[:, :, (2, 1, 0)], (256, 256), interp='bilinear')\n",
    "        images.append(img)\n",
    "        objects.append((obj1, obj2))\n",
    "    \n",
    "    for n1, chunk in enumerate(chunks(zip(images, objects), size=batch_size)):\n",
    "        _, channels, w, h = net.blobs['data'].data.shape\n",
    "        net.blobs['data'].reshape(len(chunk), channels, w, h)\n",
    "\n",
    "        for idx1, (im, _) in enumerate(chunk):\n",
    "            transformed_image = transformer.preprocess('data', im)\n",
    "            net.blobs['data'].data[idx1] = transformed_image\n",
    "\n",
    "        output = net.forward()\n",
    "        output_prob = output['softmax']\n",
    "        for idx2, prob in enumerate(output_prob):\n",
    "            prep = labels_preposition[prob.argmax()]\n",
    "            score = prob.max()\n",
    "            _, (obj1, obj2) = chunk[idx2]\n",
    "            indexed.append([scene, prediction, prep, obj1, obj2, score])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
